from langchain.prompts import ChatPromptTemplate
from langchain_community.llms.ollama import Ollama
from langchain_community.vectorstores import FAISS
from get_embedding_function2 import get_embedding_function
from datetime import datetime

PROMPT_TEMPLATE = """
You are a knowledgeable assistant and a SQL database and relations expert. Your task is to interpret metadata and configuration instructions to accurately read, understand or update the database tables by generating field values. Follow these guidelines:
 
1. Identify the tables asked to configure and generate values for all field names in the table using INSERT format.
2. Also update parent and child tables keeping primary and foreign keys in mind, Eg: If you are configuring a child table its primary key comes from the parent table, the parent table row should also be inserted. Similarly all child tables should also update accordingly.
3. Provide complete and detailed answers without using ellipses ("..."). (If you're asked for 100 rows you will give 100 rows of data. Don't be lazy.)
4. Avoid unnecessary conversation and stick to the point.
 
Stick to this Schema Information:
{table_info}

Use precise table and field names as provided in the schema. Match whole name for table names and field names. For example, if the table name is "users" it is not the same as "user".
 
##RULES##
    -Use the YYYY-MM-DD format for dates.
    -All rows to be added must be in insert query format and all rows values must be generated by you. Do not provide logic code for it. Provide direct INSERT query with multiple rows. 
    -English language is used 'ENG'.
    -Assume tables to already be created, only provide insert queries.

Question: {question}
 
Answer in detail:
"""

model = Ollama(model="llama3:instruct", temperature=0)
embedding_function = get_embedding_function()
db_tbl = FAISS.load_local("faiss_index_tbl", embedding_function, allow_dangerous_deserialization=True)

def build_context(results):
    context_texts = []

    for doc_score in results:
        doc, _score = doc_score
        context_texts.append(doc.page_content)

    context_text = "\n\n---\n\n".join(context_texts)
    return context_text


def query_rag(query_text: str):
    #Removed multithreading
    results_tbl = db_tbl.similarity_search_with_score(query_text, k=1)

    context_text_tbl = build_context(results_tbl)
    print("Tbl info context: ", context_text_tbl)

    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)
    prompt = prompt_template.format(table_info=context_text_tbl, question=query_text)

    response_text = model.invoke(prompt)
    sources = [doc.metadata.get("id", None) for doc, _score in results_tbl]
    formatted_response = f"Response: {response_text}\n\nSources: {sources}"
    print(formatted_response)
    return response_text



if __name__ == "__main__":
    start_time = datetime.now()

    query_text = "configure currency for india and uae"
    query_rag(query_text)

    end_time = datetime.now()
    execution_time = end_time - start_time
    print(f"Execution time: {execution_time}")
